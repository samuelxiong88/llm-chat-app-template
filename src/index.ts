/**
 * Worker â†’ OpenAI Responses API (SSE)
 * - å…ˆè¿”å› SSE å¤´ï¼Œéšååœ¨æµå†…å¼‚æ­¥æ‹‰ OpenAIï¼Œé¿å…æµè§ˆå™¨ç­‰ä¸åˆ°å“åº”å¤´
 * - å·¥å…·ç™½åå• + è‡ªåŠ¨å›é€€ï¼ˆweb_search_preview_2025_03_11ï¼‰
 * - ç²¾å‡†æ”¯æŒ response.web_search_call.*ï¼ˆåªæç¤ºä¸€æ¬¡/æ˜¾ç¤ºçº¿ç´¢æ¡æ•°/å®Œæˆæç¤ºï¼‰
 * - 8s å¿ƒè·³ï¼›12s é¦–åŒ…å›é€€ï¼ˆéæµå¼ã€æ— å·¥å…·ï¼‰ï¼›45s æ€»è¶…æ—¶
 * - DEBUG_DUMP=onï¼šè¾“å‡ºå‰ 5 æ¡ RAW dataï¼›DEBUG_EVENTS=onï¼šæœªçŸ¥äº‹ä»¶å¯è§åŒ–
 * - SSE è½¬æˆ chat-completions é£æ ¼ choices[0].delta.content
 */

const DEFAULT_API_BASE = "https://api.openai.com/v1";
const DEFAULT_MODEL = "gpt-4o";
const DEFAULT_SYSTEM_PROMPT = [
  "You are a senior bilingual (ä¸­è‹±åŒè¯­) analyst and writer.",
  "When the request is time-sensitive (e.g., news/today/latest/real-time), you SHOULD call the web_search tool first.",
  "Always return clean Markdown:",
  "- Use '##' for headings;",
  "- Use '-' bullets with short, actionable points;",
  "- If you relied on web context, cite sources by site name in parentheses.",
  "é»˜è®¤ç”¨ç”¨æˆ·è¯­è¨€å›ç­”ï¼›å¿…è¦æœ¯è¯­ä¿ç•™è‹±æ–‡ã€‚",
].join(" ");

const te = new TextEncoder();
const SSE_HEADERS = {
  "Content-Type": "text/event-stream; charset=utf-8",
  "Cache-Control": "no-cache",
  Connection: "keep-alive",
  "Access-Control-Allow-Origin": "*",
};

function json(obj: unknown, status = 200): Response {
  return new Response(JSON.stringify(obj), {
    status,
    headers: { "content-type": "application/json", "Access-Control-Allow-Origin": "*" },
  });
}
function sseData(o: unknown) { return te.encode(`data: ${JSON.stringify(o)}\n\n`); }
function sseDone() { return te.encode(`data: [DONE]\n\n`); }

export default {
  async fetch(request: Request, env: any): Promise<Response> {
    try {
      const url = new URL(request.url);
      const apiBase = (env.OPENAI_API_BASE || DEFAULT_API_BASE).trim();
      const model = (env.OPENAI_MODEL || DEFAULT_MODEL).trim();
      const SYSTEM_PROMPT = env.SYSTEM_PROMPT || DEFAULT_SYSTEM_PROMPT;

      const ENABLE_TOOLS = String(env.OPENAI_NATIVE_TOOLS || "").toLowerCase() === "on";
      const DEBUG_EVENTS = String(env.DEBUG_EVENTS || "").toLowerCase() === "on";
      const DEBUG_DUMP = String(env.DEBUG_DUMP || "").toLowerCase() === "on";

      // ä»…è¿™äº›æ¨¡å‹å°è¯•å¸¦æ‰˜ç®¡æœç´¢å·¥å…·ï¼›å…¶ä½™ä¸å¸¦ï¼ˆé¿å… 400ï¼‰
      const TOOL_MODELS = new Set([
        "gpt-4o",
        "gpt-4o-2024-11-20",
        "gpt-4o-mini",
        "gpt-4.1",
        "gpt-4.1-mini",
      ]);

      // å…œåº•é¡µ
      if (url.pathname === "/" || !url.pathname.startsWith("/api/")) {
        const html = `<!doctype html><meta charset="utf-8"><title>LLM Chat</title>
<body style="font-family:system-ui;margin:40px">
<h2>LLM Chat Worker</h2>
<ul>
  <li><code>/api/chat?q=hello</code></li>
  <li><code>/api/ping</code></li>
  <li><code>/api/debug</code></li>
  <li><code>/api/health</code></li>
</ul>
</body>`;
        return new Response(html, { headers: { "content-type": "text/html; charset=utf-8" } });
      }

      // CORS é¢„æ£€
      if (request.method === "OPTIONS") {
        return new Response(null, {
          headers: {
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "content-type, authorization",
            "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
            "Access-Control-Max-Age": "86400",
          },
        });
      }

      // /api/debug
      if (url.pathname === "/api/debug") {
        return json({
          OPENAI_API_KEY: env.OPENAI_API_KEY ? "set" : "not set",
          OPENAI_MODEL: env.OPENAI_MODEL || "not set",
          OPENAI_API_BASE: env.OPENAI_API_BASE || "not set",
          OPENAI_NATIVE_TOOLS: ENABLE_TOOLS ? "on" : "off",
          effective_model: model,
        });
      }

      // /api/healthï¼ˆéæµå¼ pingï¼‰
      if (url.pathname === "/api/health") {
        const payload = {
          model,
          input: [
            { role: "system", content: "Reply with 'OK' only." },
            { role: "user", content: "ping" },
          ],
          stream: false,
          max_output_tokens: 16,
        };
        const r = await fetch(`${apiBase}/responses`, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${env.OPENAI_API_KEY}`,
            "Content-Type": "application/json",
            Accept: "application/json",
            "OpenAI-Beta": env.OPENAI_BETA || "responses-2024-12-17",
          },
          body: JSON.stringify(payload),
        });
        const t = await r.text().catch(() => "");
        return new Response(t || "no-body", {
          status: r.status,
          headers: { "content-type": "application/json", "Access-Control-Allow-Origin": "*" },
        });
      }

      // /api/pingï¼ˆåˆ—æ¨¡å‹ï¼‰
      if (url.pathname === "/api/ping") {
        try {
          const r = await fetch(`${apiBase}/models`, {
            headers: { Authorization: `Bearer ${env.OPENAI_API_KEY}` },
          });
          const text = await r.text();
          return new Response(text, {
            status: r.status,
            headers: { "content-type": "application/json", "Access-Control-Allow-Origin": "*" },
          });
        } catch (e) {
          return json({ error: String(e) }, 500);
        }
      }

      // /api/chatï¼ˆæ ¸å¿ƒï¼‰
      if (url.pathname === "/api/chat") {
        // 1) ç»„è£… messages
        type Msg = { role: "system" | "user" | "assistant"; content: string };
        let messages: Msg[] = [];
        if (request.method === "GET") {
          const q = url.searchParams.get("q") || "Hello";
          messages = [{ role: "system", content: SYSTEM_PROMPT }, { role: "user", content: q }];
        } else if (request.method === "POST") {
          const body = await request.json().catch(() => ({}));
          const userMsgs = Array.isArray((body as any)?.messages) ? (body as any).messages : [];
          messages = userMsgs.length ? userMsgs : [{ role: "user", content: "Hello" }];
          if (!messages.some((m) => m.role === "system")) {
            messages.unshift({ role: "system", content: SYSTEM_PROMPT });
          }
        } else {
          return json({ error: "Method not allowed" }, 405);
        }

        // 2) å‚æ•°
        const qMax = url.searchParams.get("max_tokens") ?? url.searchParams.get("max_output_tokens");
        const qSeed = url.searchParams.get("seed");
        const qT = url.searchParams.get("temperature");
        const qTP = url.searchParams.get("top_p");

        const isThinking = /thinking/i.test(model);
        const supportsSampling = !isThinking;

        const max_output_tokens =
          qMax !== null ? Number(qMax) : env.OPENAI_MAX_TOKENS ? Number(env.OPENAI_MAX_TOKENS) : 1200;

        const seed =
          qSeed !== null ? Number(qSeed) : env.OPENAI_SEED ? Number(env.OPENAI_SEED) : undefined;

        const temperature =
          qT !== null ? Number(qT) : env.OPENAI_TEMPERATURE ? Number(env.OPENAI_TEMPERATURE) : 0.7;

        const top_p =
          qTP !== null ? Number(qTP) : env.OPENAI_TOP_P ? Number(env.OPENAI_TOP_P) : 1.0;

        // 3) åŸºæœ¬ payloadï¼ˆæš‚ä¸è¯·æ±‚ä¸Šæ¸¸ï¼‰
        const basePayload: any = {
          model,
          input: messages,
          stream: true,
          max_output_tokens,
        };
        if (typeof seed === "number" && !Number.isNaN(seed)) basePayload.seed = seed;
        if (supportsSampling) {
          basePayload.temperature = temperature;
          basePayload.top_p = top_p;
        } else {
          basePayload.reasoning = { effort: "medium" }; // thinking æ¨¡å‹æ‰ç”¨
        }
        if (ENABLE_TOOLS && TOOL_MODELS.has(model)) {
          basePayload.tools = [{ type: "web_search_preview_2025_03_11" }];
          basePayload.tool_choice = "auto";
        }

        // 4) ç«‹å³è¿”å› SSEï¼›åœ¨æµå†…å¼‚æ­¥æ‹‰ OpenAI
        const stream = new ReadableStream<Uint8Array>({
          start(controller) {
            // èµ·å§‹ï¼šåªå‘ roleï¼ˆå‰ç«¯æœ¬åœ°å ä½ä¼šæ˜¾ç¤ºâ€œæ­£åœ¨å¤„ç†â€¦â€ï¼‰
            controller.enqueue(sseData({
              id: "cmpl-start",
              object: "chat.completion.chunk",
              choices: [{ index: 0, delta: { role: "assistant" }, finish_reason: null }],
            }));

            (async () => {
              // æ€»è¶…æ—¶ & å¿ƒè·³
              const upstreamCtl = new AbortController();
              const REQUEST_TIMEOUT_MS = 45000;
              const timeoutHandle = setTimeout(() => upstreamCtl.abort("request-timeout"), REQUEST_TIMEOUT_MS);

              let lastTextTs = Date.now();
              const HEARTBEAT_MS = 8000;
              const heartbeat = setInterval(() => {
                if (Date.now() - lastTextTs > HEARTBEAT_MS) {
                  controller.enqueue(sseData({
                    id: "cmpl-chunk",
                    object: "chat.completion.chunk",
                    choices: [{ index: 0, delta: { content: "ï¼ˆä»åœ¨æ£€ç´¢ä¸æ•´åˆï¼Œè¯·ç¨å€™â€¦ï¼‰" }, finish_reason: null }],
                  }));
                  lastTextTs = Date.now();
                }
              }, HEARTBEAT_MS);

              // â€”â€”å…³é”®ï¼šåªæœ‰â€œæ­£æ–‡å¢é‡â€æ‰ç½® trueï¼›æç¤º/å¿ƒè·³ä¸ç½® true â€”â€” //
              let gotFirstText = false;        // æ˜¯å¦å·²æ”¶åˆ°â€œæ­£æ–‡å¢é‡â€
              let toolInProgressShown = false; // é¿å…â€œæ­£åœ¨æ£€ç´¢â€åˆ·å±

              const pushText = (text: string) => {
                if (!text) return;
                gotFirstText = true;
                lastTextTs = Date.now();
                controller.enqueue(sseData({
                  id: "cmpl-chunk",
                  object: "chat.completion.chunk",
                  choices: [{ index: 0, delta: { content: text }, finish_reason: null }],
                }));
              };
              const pushHint = (text: string) => {
                if (!text) return;
                lastTextTs = Date.now();
                controller.enqueue(sseData({
                  id: "cmpl-chunk",
                  object: "chat.completion.chunk",
                  choices: [{ index: 0, delta: { content: text }, finish_reason: null }],
                }));
              };
              const pushStop = () => {
                controller.enqueue(sseData({
                  id: "cmpl-stop",
                  object: "chat.completion.chunk",
                  choices: [{ index: 0, delta: {}, finish_reason: "stop" }],
                }));
                controller.enqueue(sseDone());
              };

              async function readUpstream(readable: ReadableStream<Uint8Array>) {
                const reader = readable.getReader();
                const decoder = new TextDecoder("utf-8");
                let buffer = "";
                let lastEvent = "";
                let dumpCount = 0;

                while (true) {
                  const { value, done } = await reader.read();
                  if (done) break;
                  buffer += decoder.decode(value, { stream: true });

                  const lines = buffer.split("\n");
                  buffer = lines.pop() || "";

                  for (const raw of lines) {
                    const line = raw.trim();
                    if (!line) continue;

                    if (line.startsWith("event:")) { lastEvent = line.slice(6).trim(); continue; }
                    if (!line.startsWith("data:")) continue;

                    const dataStr = line.slice(5).trim();

                    // RAW dumpï¼ˆä»…è°ƒè¯•æ—¶è¾“å‡ºå‰ 5 æ¡ï¼‰
                    if (DEBUG_DUMP && dumpCount < 5 && dataStr !== "[DONE]") {
                      dumpCount++;
                      controller.enqueue(sseData({
                        id: "cmpl-dump",
                        object: "chat.completion.chunk",
                        choices: [{ index: 0, delta: { content: `ï¼ˆRAW#${dumpCount}ï¼‰${dataStr.slice(0,300)}` }, finish_reason: null }],
                      }));
                    }

                    if (dataStr === "[DONE]") { pushStop(); return; }

                    try {
                      const obj: any = JSON.parse(dataStr);
                      const type = (obj?.type || lastEvent || obj?.event || "").toString();
                      const tLower = type.toLowerCase();

                      // â‘  æ­£æ–‡å¢é‡
                      if (type.endsWith(".delta") || type === "response.delta" || typeof obj.delta === "string") {
                        const t =
                          typeof obj.delta === "string" ? obj.delta :
                          typeof obj.text === "string"  ? obj.text  :
                          typeof obj.content === "string" ? obj.content :
                          (obj?.output_text?.content?.[0]?.text || "");
                        if (t) pushText(t);
                        continue;
                      }

                      // â‘¡ Responses web_search_call.* äº‹ä»¶ï¼ˆåªæç¤ºä¸€æ¬¡ + çº¿ç´¢æ¡æ•° + å®Œæˆï¼‰
                      if (type.startsWith("response.web_search_call")) {
                        if (/(in_progress|searching|started|created)$/i.test(tLower) && !toolInProgressShown) {
                          pushHint("ğŸ” æ­£åœ¨è”ç½‘æ£€ç´¢â€¦");
                          toolInProgressShown = true;
                          continue;
                        }
                        if (tLower.endsWith(".results") && Array.isArray(obj?.results)) {
                          pushHint(`ğŸ§­ å·²è·å– ${obj.results.length} æ¡çº¿ç´¢ï¼Œæ­£åœ¨æ•´åˆâ€¦`);
                          continue;
                        }
                        if (tLower.endsWith(".completed")) {
                          pushHint("ğŸ“„ å·²è·å–ç»“æœï¼Œæ­£åœ¨æ•´åˆâ€¦");
                          continue;
                        }
                      }

                      // â‘¢ å…¶å®ƒå·¥å…·/è¿›åº¦ç±»äº‹ä»¶
                      if (/(tool_call|tool)\.(started|created)/i.test(tLower) && !toolInProgressShown) {
                        pushHint("ğŸ” æ­£åœ¨è”ç½‘æ£€ç´¢â€¦");
                        toolInProgressShown = true;
                        continue;
                      }
                      if (/(tool_call|tool)\.(completed|finish|finished)/i.test(tLower)) {
                        pushHint("ğŸ“„ å·²è·å–ç»“æœï¼Œæ­£åœ¨æ•´åˆâ€¦");
                        continue;
                      }
                      if (/progress|working|searching|retrieving/i.test(tLower)) {
                        pushHint("ï¼ˆæ£€ç´¢è¿›è¡Œä¸­â€¦ï¼‰");
                        continue;
                      }

                      // â‘£ å®Œæˆ
                      if (type.endsWith(".done") || type === "response.completed" || obj?.done === true) {
                        pushStop(); return;
                      }

                      // â‘¤ æœªçŸ¥äº‹ä»¶å¯è§åŒ–ï¼ˆå¯é€‰ï¼‰
                      if (DEBUG_EVENTS && type) pushHint(`ï¼ˆäº‹ä»¶ï¼š${type}ï¼‰`);
                    } catch { /* é JSON è¡Œå¿½ç•¥ï¼ˆæˆ–é  RAW dumpï¼‰ */ }
                  }
                }
              }

              try {
                const headers = {
                  Authorization: `Bearer ${env.OPENAI_API_KEY}`,
                  "Content-Type": "application/json",
                  Accept: "text/event-stream",
                  "OpenAI-Beta": (env.OPENAI_BETA || "responses-2024-12-17") + "; tools=v1",
                };

                // ç¬¬ä¸€æ¬¡ï¼ˆå¯èƒ½å¸¦å·¥å…·ï¼‰
                let payload = basePayload;
                let upstream = await fetch(`${apiBase}/responses`, {
                  method: "POST", headers, body: JSON.stringify(payload), signal: upstreamCtl.signal,
                });

                // 400 â†’ è‡ªåŠ¨å›é€€ï¼ˆtools/å‚æ•°ä¸è¢«æ”¯æŒï¼‰
                if (!upstream.ok) {
                  const firstDetail = await upstream.text().catch(() => "");
                  const lower = firstDetail.toLowerCase();
                  const toolsProblem =
                    upstream.status === 400 && (
                      (/invalid_value/.test(lower) && /tools/.test(lower)) ||
                      (/not supported with/.test(lower) && /tool/.test(lower)) ||
                      (/unsupported/.test(lower) && /tool/.test(lower)) ||
                      /unknown tool/.test(lower) ||
                      (/param/.test(lower) && /tools/.test(lower))
                    );
                  const badSampling =
                    upstream.status === 400 && /unsupported/.test(lower) && /(temperature|top_p)/i.test(lower);
                  const badReasoning =
                    upstream.status === 400 && /unsupported/.test(lower) && /reasoning\.effort/i.test(lower);

                  if (toolsProblem || badSampling || badReasoning) {
                    payload = { model, input: messages, stream: true, max_output_tokens };
                    upstream = await fetch(`${apiBase}/responses`, {
                      method: "POST", headers, body: JSON.stringify(payload), signal: upstreamCtl.signal,
                    });
                  } else {
                    pushHint(`âš ï¸ Upstream ${upstream.status}: ${firstDetail.slice(0,800)}`);
                    pushStop(); clearInterval(heartbeat); clearTimeout(timeoutHandle); controller.close(); return;
                  }
                }

                if (!upstream.ok || !upstream.body) {
                  const detail = await upstream.text().catch(() => "");
                  pushHint(`âš ï¸ Upstream error: ${detail.slice(0,800)}`);
                  pushStop(); clearInterval(heartbeat); clearTimeout(timeoutHandle); controller.close(); return;
                }

                // â€”â€”é¦–åŒ…çœ‹é—¨ç‹—ï¼š12s å†…æœªæ”¶åˆ°â€œæ­£æ–‡â€ï¼Œå›é€€ä¸ºéæµå¼ã€æ— å·¥å…·â€”â€”
                const FIRST_PACKET_MS = 12000;
                const firstPacketTimer = setTimeout(async () => {
                  if (gotFirstText) return; // çœŸæ­£æ­£æ–‡å·²åˆ°ï¼Œä¸å›é€€

                  try { upstreamCtl.abort(); } catch {}

                  const headersJSON = {
                    Authorization: `Bearer ${env.OPENAI_API_KEY}`,
                    "Content-Type": "application/json",
                    Accept: "application/json",
                    "OpenAI-Beta": env.OPENAI_BETA || "responses-2024-12-17",
                  };
                  const fb: any = { model, input: messages, stream: false, max_output_tokens };
                  const r = await fetch(`${apiBase}/responses`, {
                    method: "POST", headers: headersJSON, body: JSON.stringify(fb),
                  });
                  const txt = await r.text().catch(() => "");
                  if (!r.ok || !txt) {
                    pushHint(`ï¼ˆéæµå¼å›é€€å¤±è´¥ï¼‰${txt.slice(0,600)}`);
                    pushStop(); clearInterval(heartbeat); clearTimeout(timeoutHandle); controller.close(); return;
                  }
                  let out = "";
                  try {
                    const j = JSON.parse(txt);
                    out =
                      j?.output_text?.[0]?.content?.[0]?.text ||
                      j?.output?.[0]?.content?.[0]?.text ||
                      j?.choices?.[0]?.message?.content || "";
                  } catch {}
                  if (!out) out = txt.slice(0,2000);

                  pushText(out);
                  pushStop(); clearInterval(heartbeat); clearTimeout(timeoutHandle); controller.close();
                }, FIRST_PACKET_MS);

                // è¯»å–ä¸Šæ¸¸æµ
                await readUpstream(upstream.body);
                clearTimeout(firstPacketTimer);

                clearInterval(heartbeat); clearTimeout(timeoutHandle);
                if (!gotFirstText) pushStop();
                controller.close();
              } catch (e) {
                pushHint(`âš ï¸ Worker error: ${String(e).slice(0,200)}`);
                pushStop(); controller.close();
              }
            })();
          },
        });

        return new Response(stream, { headers: SSE_HEADERS });
      }

      return json({ error: "Not found" }, 404);
    } catch (e) {
      return json({ error: "Worker exception", detail: String(e) }, 500);
    }
  },
};
