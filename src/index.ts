/**
 * Worker â†’ OpenAI Responses API (SSE)
 * - å…ˆè¿”å› SSE å¤´ï¼Œå†åœ¨æµå†…å¼‚æ­¥æ‹‰ OpenAIï¼Œé¿å…æµè§ˆå™¨ç­‰ä¸åˆ°å“åº”å¤´
 * - å·¥å…·ç™½åå• + è‡ªåŠ¨å›é€€ï¼ˆweb_search_preview_2025_03_11ï¼‰
 * - ç²¾å‡†æ”¯æŒ response.web_search_call.* äº‹ä»¶ï¼šåªæç¤ºä¸€æ¬¡ï¼Œæ˜¾ç¤ºæ¡æ•°ä¸å®ŒæˆçŠ¶æ€
 * - 8s å¿ƒè·³ï¼›45s æ€»è¶…æ—¶ï¼›12s é¦–åŒ…å›é€€ä¸ºéæµå¼
 * - DEBUG_DUMP=on: è¾“å‡ºå‰ 5 æ¡ RAW data è¡Œç”¨äºæ’é”™
 * - SSE è½¬æˆ chat-completions é£æ ¼ choices[0].delta.content
 */

const DEFAULT_API_BASE = "https://api.openai.com/v1";
const DEFAULT_MODEL = "gpt-4o";
const DEFAULT_SYSTEM_PROMPT = [
  "You are a senior bilingual (ä¸­è‹±åŒè¯­) analyst and writer.",
  "When content is time-sensitive (news/today/latest/real-time), you SHOULD call the web_search tool first.",
  "Always return clean Markdown:",
  "- Use '##' headings;",
  "- Use '-' bullet lists; short, actionable points;",
  "- Cite sources by site name in parentheses if you relied on the web context.",
  "é»˜è®¤ç”¨ç”¨æˆ·è¯­è¨€å›ç­”ï¼›å¿…è¦æœ¯è¯­ä¿ç•™è‹±æ–‡ã€‚",
].join(" ");

const te = new TextEncoder();
const SSE_HEADERS = {
  "Content-Type": "text/event-stream; charset=utf-8",
  "Cache-Control": "no-cache",
  Connection: "keep-alive",
  "Access-Control-Allow-Origin": "*",
};

function json(obj: unknown, status = 200): Response {
  return new Response(JSON.stringify(obj), {
    status,
    headers: { "content-type": "application/json", "Access-Control-Allow-Origin": "*" },
  });
}
function sseData(o: unknown) { return te.encode(`data: ${JSON.stringify(o)}\n\n`); }
function sseDone() { return te.encode(`data: [DONE]\n\n`); }

export default {
  async fetch(request: Request, env: any): Promise<Response> {
    try {
      const url = new URL(request.url);
      const apiBase = (env.OPENAI_API_BASE || DEFAULT_API_BASE).trim();
      const model = (env.OPENAI_MODEL || DEFAULT_MODEL).trim();
      const SYSTEM_PROMPT = env.SYSTEM_PROMPT || DEFAULT_SYSTEM_PROMPT;

      const ENABLE_TOOLS = String(env.OPENAI_NATIVE_TOOLS || "").toLowerCase() === "on";
      const DEBUG_EVENTS = String(env.DEBUG_EVENTS || "").toLowerCase() === "on";
      const DEBUG_DUMP = String(env.DEBUG_DUMP || "").toLowerCase() === "on";

      // ä»…è¿™äº›æ¨¡å‹å°è¯•å¸¦æ‰˜ç®¡æœç´¢å·¥å…·ï¼›å…¶ä½™ä¸å¸¦ï¼ˆé¿å… 400ï¼‰
      const TOOL_MODELS = new Set([
        "gpt-4o",
        "gpt-4o-2024-11-20",
        "gpt-4o-mini",
        "gpt-4.1",
        "gpt-4.1-mini",
      ]);

      // æ ¹è·¯å¾„ â†’ å…œåº•é¡µ
      if (url.pathname === "/" || !url.pathname.startsWith("/api/")) {
        return new Response("<h2>LLM Chat Worker</h2>", { headers: { "content-type": "text/html" } });
      }

      // /api/debug
      if (url.pathname === "/api/debug") {
        return json({
          OPENAI_API_KEY: env.OPENAI_API_KEY ? "set" : "not set",
          OPENAI_MODEL: env.OPENAI_MODEL || "not set",
          OPENAI_API_BASE: env.OPENAI_API_BASE || "not set",
          OPENAI_NATIVE_TOOLS: ENABLE_TOOLS ? "on" : "off",
          effective_model: model,
        });
      }

      // /api/chat
      if (url.pathname === "/api/chat") {
        // ç»„è£… messages
        type Msg = { role: "system" | "user" | "assistant"; content: string };
        let messages: Msg[] = [];
        if (request.method === "GET") {
          const q = url.searchParams.get("q") || "Hello";
          messages = [{ role: "system", content: SYSTEM_PROMPT }, { role: "user", content: q }];
        } else if (request.method === "POST") {
          const body = await request.json().catch(() => ({}));
          const userMsgs = Array.isArray((body as any)?.messages) ? (body as any).messages : [];
          messages = userMsgs.length ? userMsgs : [{ role: "user", content: "Hello" }];
          if (!messages.some((m) => m.role === "system")) {
            messages.unshift({ role: "system", content: SYSTEM_PROMPT });
          }
        } else {
          return json({ error: "Method not allowed" }, 405);
        }

        // payload
        const basePayload: any = {
          model,
          input: messages,
          stream: true,
          max_output_tokens: 1200,
        };
        if (ENABLE_TOOLS && TOOL_MODELS.has(model)) {
          basePayload.tools = [{ type: "web_search_preview_2025_03_11" }];
          basePayload.tool_choice = "auto";
        }

        // SSE
        const stream = new ReadableStream<Uint8Array>({
          start(controller) {
            controller.enqueue(sseData({
              id: "cmpl-start",
              object: "chat.completion.chunk",
              choices: [{ index: 0, delta: { role: "assistant" }, finish_reason: null }],
            }));

            (async () => {
              const upstreamCtl = new AbortController();
              const timeoutHandle = setTimeout(() => upstreamCtl.abort("request-timeout"), 45000);
              let lastTextTs = Date.now();
              const heartbeat = setInterval(() => {
                if (Date.now() - lastTextTs > 8000) {
                  controller.enqueue(sseData({
                    id: "cmpl-chunk",
                    object: "chat.completion.chunk",
                    choices: [{ index: 0, delta: { content: "ï¼ˆä»åœ¨æ£€ç´¢ä¸æ•´åˆï¼Œè¯·ç¨å€™â€¦ï¼‰" }, finish_reason: null }],
                  }));
                  lastTextTs = Date.now();
                }
              }, 8000);

              let gotFirstText = false;
              let toolInProgressShown = false;

              const pushDelta = (text: string) => {
                if (!text) return;
                gotFirstText = true;
                lastTextTs = Date.now();
                controller.enqueue(sseData({
                  id: "cmpl-chunk",
                  object: "chat.completion.chunk",
                  choices: [{ index: 0, delta: { content: text }, finish_reason: null }],
                }));
              };
              const pushStop = () => {
                controller.enqueue(sseData({
                  id: "cmpl-stop",
                  object: "chat.completion.chunk",
                  choices: [{ index: 0, delta: {}, finish_reason: "stop" }],
                }));
                controller.enqueue(sseDone());
              };

              async function readUpstream(readable: ReadableStream<Uint8Array>) {
                const reader = readable.getReader();
                const decoder = new TextDecoder("utf-8");
                let buffer = "";
                let lastEvent = "";
                let dumpCount = 0;
                while (true) {
                  const { value, done } = await reader.read();
                  if (done) break;
                  buffer += decoder.decode(value, { stream: true });
                  const lines = buffer.split("\n");
                  buffer = lines.pop() || "";
                  for (const raw of lines) {
                    const line = raw.trim();
                    if (!line) continue;
                    if (line.startsWith("event:")) { lastEvent = line.slice(6).trim(); continue; }
                    if (!line.startsWith("data:")) continue;
                    const dataStr = line.slice(5).trim();

                    // RAW dump
                    if (DEBUG_DUMP && dumpCount < 5 && dataStr !== "[DONE]") {
                      dumpCount++;
                      controller.enqueue(sseData({
                        id: "cmpl-dump",
                        object: "chat.completion.chunk",
                        choices: [{ index: 0, delta: { content: `ï¼ˆRAW#${dumpCount}ï¼‰${dataStr.slice(0, 300)}` }, finish_reason: null }],
                      }));
                    }

                    if (dataStr === "[DONE]") { pushStop(); return; }

                    try {
                      const obj: any = JSON.parse(dataStr);
                      const type = (obj?.type || lastEvent || obj?.event || "").toString();
                      const tLower = type.toLowerCase();

                      // æ–‡æœ¬å¢é‡
                      if (type.endsWith(".delta") || type === "response.delta" || typeof obj.delta === "string") {
                        const t =
                          typeof obj.delta === "string" ? obj.delta :
                          typeof obj.text === "string" ? obj.text :
                          typeof obj.content === "string" ? obj.content :
                          (obj?.output_text?.content?.[0]?.text || "");
                        if (t) pushDelta(t);
                        continue;
                      }

                      // === Responses web_search_call.* ç²¾å‡†æç¤º ===
                      if (type.startsWith("response.web_search_call")) {
                        if (/in_progress|searching|started|created/i.test(tLower) && !toolInProgressShown) {
                          pushDelta("ğŸ” æ­£åœ¨è”ç½‘æ£€ç´¢â€¦");
                          toolInProgressShown = true;
                          continue;
                        }
                        if (/results$/i.test(tLower) && Array.isArray(obj?.results)) {
                          pushDelta(`ğŸ§­ å·²è·å– ${obj.results.length} æ¡çº¿ç´¢ï¼Œæ­£åœ¨æ•´åˆâ€¦`);
                          continue;
                        }
                        if (/completed$/i.test(tLower)) {
                          pushDelta("ğŸ“„ å·²è·å–ç»“æœï¼Œæ­£åœ¨æ•´åˆâ€¦");
                          continue;
                        }
                      }

                      // å®Œæˆ
                      if (type.endsWith(".done") || type === "response.completed" || obj?.done === true) {
                        pushStop(); return;
                      }

                      // æœªçŸ¥äº‹ä»¶å¯è§åŒ–
                      if (DEBUG_EVENTS && type) pushDelta(`ï¼ˆäº‹ä»¶ï¼š${type}ï¼‰`);
                    } catch { /* é JSON */ }
                  }
                }
              }

              try {
                const headers = {
                  Authorization: `Bearer ${env.OPENAI_API_KEY}`,
                  "Content-Type": "application/json",
                  Accept: "text/event-stream",
                  "OpenAI-Beta": (env.OPENAI_BETA || "responses-2024-12-17") + "; tools=v1",
                };
                const upstream = await fetch(`${apiBase}/responses`, {
                  method: "POST", headers, body: JSON.stringify(basePayload), signal: upstreamCtl.signal,
                });
                if (!upstream.ok || !upstream.body) {
                  const detail = await upstream.text().catch(() => "");
                  pushDelta(`âš ï¸ Upstream error: ${detail.slice(0, 800)}`);
                  pushStop(); controller.close(); return;
                }
                await readUpstream(upstream.body);
              } catch (e) {
                pushDelta(`âš ï¸ Worker error: ${String(e).slice(0, 200)}`);
                pushStop(); controller.close();
              } finally {
                clearInterval(heartbeat); clearTimeout(timeoutHandle);
                controller.close();
              }
            })();
          },
        });

        return new Response(stream, { headers: SSE_HEADERS });
      }

      return json({ error: "Not found" }, 404);
    } catch (e) {
      return json({ error: "Worker exception", detail: String(e) }, 500);
    }
  },
};
